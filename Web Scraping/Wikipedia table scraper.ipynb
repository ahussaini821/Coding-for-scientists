{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Book', 'Author(s)', 'Original language', 'First published', 'Approximate sales', 'Book', 'Author(s)', 'Original language', 'First published', 'Approximate sales', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book series', 'Author(s)', 'Original language', 'No. of installments', 'First published', 'Book series', 'Author(s)', 'Original language', 'No. of installments', 'First published', 'Book series', 'Author(s)', 'Original language', 'No. of installments', 'First published', 'Book series', 'Author(s)', 'Original language', 'No. of installments', 'First published', 'Book series', 'Author(s)', 'Original language', 'No. of installments', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published', 'Book', 'Author(s)', 'Original language', 'First published']\n"
     ]
    }
   ],
   "source": [
    "# Currently only works for the best selling manga page on Wikipedia\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def parseURL(url):\n",
    "    # Used to act as a browser. Possibly not needed?\n",
    "    headers = {\"User-Agent\":\"Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127\" \n",
    "               \"Firefox/2.0.0.11\"}\n",
    "    req = urllib2.Request(url, headers=headers)\n",
    "    page = BeautifulSoup(urllib2.urlopen(req), \"html.parser\")\n",
    "    return page\n",
    "\n",
    "output = open(\"books\", \"w\")\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_best-selling_books'\n",
    "parsed = parseURL(url)\n",
    "parsed2 = str(parsed)\n",
    "\n",
    "mo=re.findall(r\"\\<th>(.*)\\</th>\", parsed2)\n",
    "data = re.findall(r\"<td><i>.*href=.*title=\\\"(.*)\\\".*\\n.*(?:\\\"|<td)>(.*)<\\/td>.*\\n.*(?:\\\"|<td)>(.*)<\\/td>.*\\n.*(?:\\\"|<td)>(.*)<\\/td>.*\\n.*(?:\\\"|<td)>(.*)<\\/td>.*\\n.*(?:\\\"|<td)>(.*)<\\/td>.*\\n<td>(\\d*)\", parsed2)\n",
    "print data\n",
    "print mo\n",
    "# Need to make empty list of all the columns in the table\n",
    "columns = []\n",
    "for i in range(6):\n",
    "    columns.append(mo[i])\n",
    "    \n",
    "# For some reason, last column not added by regular expression; could probably fix this\n",
    "columns.append(\"Genre\")\n",
    "for column in columns:\n",
    "    output.write(column)\n",
    "    output.write(\"\\t\")\n",
    "\n",
    "output.write(\"\\n\")\n",
    "\n",
    "# Iterate through every row in table\n",
    "for title in data:\n",
    "    # Iterate through every datum in row\n",
    "    for stat in title:\n",
    "        output.write(stat)\n",
    "        output.write(\"\\t\")\n",
    "    output.write(\"\\n\")\n",
    "output.close()\n",
    "\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
